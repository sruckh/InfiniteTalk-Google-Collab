{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# 1. Clone Repository (Safe to re-run)\n",
    "if not os.path.exists(\"InfiniteTalk\"):\n",
    "    !git clone https://github.com/MeiGen-AI/InfiniteTalk\n",
    "else:\n",
    "    print(\"Repository already cloned.\")\n",
    "\n",
    "# 2. Enter Directory (Required after every restart)\n",
    "%cd InfiniteTalk\n",
    "\n",
    "# 3. Safe Dependency Installation\n",
    "py_ver = f\"cp{sys.version_info.major}{sys.version_info.minor}\"\n",
    "torch_ver = torch.__version__.split('+')[0]\n",
    "# Extract major.minor for wheel matching (e.g., 2.9)\n",
    "torch_ver_short = \".\".join(torch_ver.split(\".\")[:2])\n",
    "cuda_ver = torch.version.cuda.replace('.', '')[:3] if torch.version.cuda else \"cpu\"\n",
    "abi = \"TRUE\" if torch._C._GLIBCXX_USE_CXX11_ABI else \"FALSE\"\n",
    "\n",
    "print(f\"✅ Detected: Python={py_ver}, Torch={torch_ver} (Short: {torch_ver_short}), CUDA={cuda_ver}, ABI={abi}\")\n",
    "print(\"Installing dependencies... (Fast mode enabled)\")\n",
    "\n",
    "# Install dependencies needed for extensions\n",
    "!pip install --no-cache-dir packaging ninja psutil wheel\n",
    "\n",
    "# Install Flash Attention 2 (Dynamic Wheel Selection)\n",
    "try:\n",
    "    import flash_attn\n",
    "    print(\"✅ Flash Attention already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing Flash Attention...\")\n",
    "    try:\n",
    "        # Attempt to construct the specific wheel URL for Colab (usually cxx11abiFALSE)\n",
    "        # Adjust this version to match the latest available release\n",
    "        fa_version = \"2.8.3\"\n",
    "        \n",
    "        # Construct URL based on detected environment\n",
    "        # Note: We guess 'cu12' because often cu121/cu122/cu123 all share the same 'cu12' wheel in some repos,\n",
    "        # but official releases usually have specific tags. We will try a few likely candidates.\n",
    "        \n",
    "        # Candidate 1: Official naming convention for PyTorch 2.9 (if available)\n",
    "        # Example: flash_attn-2.8.3+cu12torch2.9cxx11abiFALSE-cp311-cp311-linux_x86_64.whl\n",
    "        wheel_filename = f\"flash_attn-{fa_version}+cu12torch{torch_ver_short}cxx11abi{abi}-{py_ver}-{py_ver}-linux_x86_64.whl\"\n",
    "        url = f\"https://github.com/Dao-AILab/flash-attention/releases/download/v{fa_version}/{wheel_filename}\"\n",
    "        \n",
    "        print(f\"Attempting to install from predicted URL: {url}\")\n",
    "        !pip install --no-cache-dir {url}\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Direct wheel install failed: {e}\")\n",
    "        print(\"Trying standard pip install (this might trigger a slow build)...\")\n",
    "        !pip install flash-attn --no-build-isolation\n",
    "\n",
    "# Install other dependencies from requirements.txt\n",
    "!sed -i 's/numpy>=1.23.5,<2/numpy>=1.23.5/' requirements.txt\n",
    "!pip install --no-cache-dir -r requirements.txt\n",
    "!pip install --no-cache-dir librosa huggingface_hub\n",
    "\n",
    "# Install system dependencies\n",
    "!apt-get update && apt-get install -y ffmpeg > /dev/null 2>&1\n",
    "\n",
    "print(\"\\n✅ Setup Complete! If you see a 'Restart Session' button, you can IGNORE it and try running the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nos.makedirs(\"weights\", exist_ok=True)\n\n# Download base model and InfiniteTalk weights\n!hf download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./weights/Wan2.1-I2V-14B-480P\n!hf download MeiGen-AI/InfiniteTalk --local-dir ./weights/InfiniteTalk\n\n# Download English audio encoder (DEFAULT)\n!hf download facebook/wav2vec2-base-960h --local-dir ./weights/wav2vec2-base-960h\n\n# Alternative: For Chinese audio support, uncomment the lines below:\n# !hf download TencentGameMate/chinese-wav2vec2-base --local-dir ./weights/chinese-wav2vec2-base\n# !hf download TencentGameMate/chinese-wav2vec2-base model.safetensors --revision refs/pr/1 --local-dir ./weights/chinese-wav2vec2-base"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Enable public link for Gradio\n!sed -i 's/demo.launch(server_name=\"0.0.0.0\", debug=True, server_port=8418)/demo.launch(server_name=\"0.0.0.0\", debug=True, server_port=8418, share=True)/' app.py\n\n# Launch Gradio interface with English audio encoder (DEFAULT)\n!python app.py --ckpt_dir weights/Wan2.1-I2V-14B-480P --wav2vec_dir 'weights/wav2vec2-base-960h' --infinitetalk_dir weights/InfiniteTalk/single/infinitetalk.safetensors --num_persistent_param_in_dit 0 --motion_frame 9\n\n# Alternative: For Chinese audio, uncomment below and comment the English line above:\n# !python app.py --ckpt_dir weights/Wan2.1-I2V-14B-480P --wav2vec_dir 'weights/chinese-wav2vec2-base' --infinitetalk_dir weights/InfiniteTalk/single/infinitetalk.safetensors --num_persistent_param_in_dit 0 --motion_frame 9"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}