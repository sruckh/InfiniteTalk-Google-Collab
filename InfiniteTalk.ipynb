{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# 1. Clone Repository (Safe to re-run)\n",
    "if not os.path.exists(\"InfiniteTalk\"):\n",
    "    !git clone https://github.com/MeiGen-AI/InfiniteTalk\n",
    "else:\n",
    "    print(\"Repository already cloned.\")\n",
    "\n",
    "# 2. Enter Directory (Required after every restart)\n",
    "%cd InfiniteTalk\n",
    "\n",
    "# 3. Safe Dependency Installation\n",
    "py_ver = f\"cp{sys.version_info.major}{sys.version_info.minor}\"\n",
    "torch_ver = torch.__version__.split('+')[0]\n",
    "torch_ver_short = \".\".join(torch_ver.split(\".\")[:2])\n",
    "cuda_ver = torch.version.cuda.replace('.', '')[:3] if torch.version.cuda else \"cpu\"\n",
    "abi = \"TRUE\" if torch._C._GLIBCXX_USE_CXX11_ABI else \"FALSE\"\n",
    "\n",
    "print(f\"✅ Detected: Python={py_ver}, Torch={torch_ver}, CUDA={cuda_ver}, ABI={abi}\")\n",
    "print(\"Installing dependencies... (Fast mode enabled)\")\n",
    "\n",
    "# Install dependencies needed for extensions\n",
    "!pip install --no-cache-dir packaging ninja psutil wheel\n",
    "\n",
    "# Install Flash Attention 2 (Dynamic Wheel Selection)\n",
    "try:\n",
    "    import flash_attn\n",
    "    print(\"✅ Flash Attention already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing Flash Attention...\")\n",
    "    # We try 2.8.3 (Best for Torch 2.9/2.10) then 2.7.4.post1 (Fallback)\n",
    "    success = False\n",
    "    # Common CUDA tags in wheels are often 'cu12' for any 12.x or 'cu130' for 13.0\n",
    "    cu_tags = [f\"cu{cuda_ver[:2]}\", f\"cu{cuda_ver}\", \"cu12\", \"cu130\"]\n",
    "    \n",
    "    for fa_v in [\"2.8.3\", \"2.7.4.post1\"]:\n",
    "        if success: break\n",
    "        for cu_tag in cu_tags:\n",
    "            wheel = f\"flash_attn-{fa_v}+{cu_tag}torch{torch_ver_short}cxx11abi{abi}-{py_ver}-{py_ver}-linux_x86_64.whl\"\n",
    "            # Release URLs usually don't have .post1 in the tag but do in the filename\n",
    "            release_tag = f\"v{fa_v.split('.post')[0]}\"\n",
    "            url = f\"https://github.com/Dao-AILab/flash-attention/releases/download/{release_tag}/{wheel}\"\n",
    "            \n",
    "            print(f\"Trying: {url}\")\n",
    "            res = os.system(f\"pip install --no-cache-dir {url}\")\n",
    "            if res == 0:\n",
    "                print(f\"✅ Successfully installed Flash Attention {fa_v} via wheel\")\n",
    "                success = True\n",
    "                break\n",
    "    \n",
    "    if not success:\n",
    "        print(\"⚠️ No matching wheel found. Falling back to slow source build...\")\n",
    "        !pip install flash-attn --no-build-isolation\n",
    "\n",
    "# Install other dependencies from requirements.txt\n",
    "!sed -i 's/numpy>=1.23.5,<2/numpy>=1.23.5/' requirements.txt\n",
    "!pip install --no-cache-dir -r requirements.txt\n",
    "!pip install --no-cache-dir librosa huggingface_hub\n",
    "\n",
    "# Install system dependencies\n",
    "!apt-get update && apt-get install -y ffmpeg > /dev/null 2>&1\n",
    "\n",
    "print(\"\\n✅ Setup Complete! If you see a 'Restart Session' button, you can IGNORE it and try running the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nos.makedirs(\"weights\", exist_ok=True)\n\n# Download base model and InfiniteTalk weights\n!hf download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./weights/Wan2.1-I2V-14B-480P\n!hf download MeiGen-AI/InfiniteTalk --local-dir ./weights/InfiniteTalk\n\n# Download English audio encoder (DEFAULT)\n!hf download facebook/wav2vec2-base-960h --local-dir ./weights/wav2vec2-base-960h\n\n# Alternative: For Chinese audio support, uncomment the lines below:\n# !hf download TencentGameMate/chinese-wav2vec2-base --local-dir ./weights/chinese-wav2vec2-base\n# !hf download TencentGameMate/chinese-wav2vec2-base model.safetensors --revision refs/pr/1 --local-dir ./weights/chinese-wav2vec2-base"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Enable public link for Gradio\n!sed -i 's/demo.launch(server_name=\"0.0.0.0\", debug=True, server_port=8418)/demo.launch(server_name=\"0.0.0.0\", debug=True, server_port=8418, share=True)/' app.py\n\n# Launch Gradio interface with English audio encoder (DEFAULT)\n!python app.py --ckpt_dir weights/Wan2.1-I2V-14B-480P --wav2vec_dir 'weights/wav2vec2-base-960h' --infinitetalk_dir weights/InfiniteTalk/single/infinitetalk.safetensors --num_persistent_param_in_dit 0 --motion_frame 9\n\n# Alternative: For Chinese audio, uncomment below and comment the English line above:\n# !python app.py --ckpt_dir weights/Wan2.1-I2V-14B-480P --wav2vec_dir 'weights/chinese-wav2vec2-base' --infinitetalk_dir weights/InfiniteTalk/single/infinitetalk.safetensors --num_persistent_param_in_dit 0 --motion_frame 9"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}